{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5727f30e-6d72-4ff1-b47c-20e13af635ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277cb61f-9894-42a6-b3e7-f62b3265dc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy206/.conda/envs/cent7/2020.11-py38/NWRGAE/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import seaborn as sb\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import statistics\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "from dgl.data import CitationGraphDataset\n",
    "# from dgl.nn import GINConv, GraphConv, SAGEConv\n",
    "import seaborn as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn as sk\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch_geometric.nn import GCNConv,GINConv,SAGEConv,GATConv,PNAConv, GraphSAGE\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.transforms import normalize_features\n",
    "from pygod.utils import load_data\n",
    "from pygod.utils.utility import check_parameter\n",
    "from pygod.metrics import eval_roc_auc\n",
    "from pygod.generator import gen_contextual_outliers, gen_structural_outliers\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57a8a0f6-41cb-4b22-9192-418310bf8923",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a1f108-b244-4fed-92da-07a65c574a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _normalize(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x_norm = (x - x_min)/x_max\n",
    "    return x_norm\n",
    "\n",
    "def gen_joint_structural_outliers(data, m, n, random_state=None):\n",
    "    \"\"\"\n",
    "    We randomly select n nodes from the network which will be the anomalies \n",
    "    and for each node we select m nodes from the network. \n",
    "    We connect each of n nodes with the m other nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : PyTorch Geometric Data instance (torch_geometric.data.Data)\n",
    "        The input data.\n",
    "    m : int\n",
    "        Number nodes in the outlier cliques.\n",
    "    n : int\n",
    "        Number of outlier cliques.\n",
    "    p : int, optional\n",
    "        Probability of edge drop in cliques. Default: ``0``.\n",
    "    random_state : int, optional\n",
    "        The seed to control the randomness, Default: ``None``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : PyTorch Geometric Data instance (torch_geometric.data.Data)\n",
    "        The structural outlier graph with injected edges.\n",
    "    y_outlier : torch.Tensor\n",
    "        The outlier label tensor where 1 represents outliers and 0 represents\n",
    "        regular nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, Data):\n",
    "        raise TypeError(\"data should be torch_geometric.data.Data\")\n",
    "\n",
    "    if isinstance(m, int):\n",
    "        check_parameter(m, low=0, high=data.num_nodes, param_name='m')\n",
    "    else:\n",
    "        raise ValueError(\"m should be int, got %s\" % m)\n",
    "\n",
    "    if isinstance(n, int):\n",
    "        check_parameter(n, low=0, high=data.num_nodes, param_name='n')\n",
    "    else:\n",
    "        raise ValueError(\"n should be int, got %s\" % n)\n",
    "\n",
    "    check_parameter(m * n, low=0, high=data.num_nodes, param_name='m*n')\n",
    "\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "\n",
    "    outlier_idx = np.random.choice(data.num_nodes, size=n, replace=False)\n",
    "    all_nodes = [i for i in range(data.num_nodes)]\n",
    "    rem_nodes = []\n",
    "    \n",
    "    for node in all_nodes:\n",
    "        if node is not outlier_idx:\n",
    "            rem_nodes.append(node)\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_edges = []\n",
    "    \n",
    "    # connect all m nodes in each clique\n",
    "    for i in range(0, n):\n",
    "        other_idx = np.random.choice(data.num_nodes, size=m, replace=False)\n",
    "        for j in other_idx:\n",
    "            new_edges.append(torch.tensor([[i, j]], dtype=torch.long))\n",
    "                    \n",
    "\n",
    "    new_edges = torch.cat(new_edges)\n",
    "\n",
    "\n",
    "    y_outlier = torch.zeros(data.x.shape[0], dtype=torch.long)\n",
    "    y_outlier[outlier_idx] = 1\n",
    "\n",
    "    data.edge_index = torch.cat([data.edge_index, new_edges.T], dim=1)\n",
    "\n",
    "    return data, y_outlier\n",
    "\n",
    "\n",
    "def KL_neighbor_loss(predictions, targets, mask_len):\n",
    "    x1 = predictions.squeeze().cpu().detach()\n",
    "    x2 = targets.squeeze().cpu().detach()\n",
    "    \n",
    "    mean_x1 = x1.mean(0)\n",
    "    mean_x2 = x2.mean(0)\n",
    "    \n",
    "    nn = x1.shape[0]\n",
    "    h_dim = x1.shape[1]\n",
    "    \n",
    "    cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / max((nn-1),1)\n",
    "    cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / max((nn-1),1)\n",
    "    \n",
    "    eye = torch.eye(h_dim)\n",
    "    cov_x1 = cov_x1 + eye\n",
    "    cov_x2 = cov_x2 + eye\n",
    "    \n",
    "    KL_loss = 0.5 * (math.log(torch.det(cov_x1) / torch.det(cov_x2)) - h_dim  + torch.trace(torch.inverse(cov_x2).matmul(cov_x1)) \n",
    "            + (mean_x2 - mean_x1).reshape(1,-1).matmul(torch.inverse(cov_x2)).matmul(mean_x2 - mean_x1))\n",
    "    KL_loss = KL_loss.to(device)\n",
    "    return KL_loss\n",
    "\n",
    "def W2_neighbor_loss(predictions, targets, mask_len):\n",
    "    \n",
    "    x1 = predictions.squeeze().cpu().detach()\n",
    "    x2 = targets.squeeze().cpu().detach()\n",
    "    \n",
    "    mean_x1 = x1.mean(0)\n",
    "    mean_x2 = x2.mean(0)\n",
    "\n",
    "    nn = x1.shape[0]\n",
    "    \n",
    "    cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / (nn-1)\n",
    "    cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / (nn-1)\n",
    "    \n",
    "\n",
    "    W2_loss = torch.square(mean_x1-mean_x2).sum() + torch.trace(cov_x1 + cov_x2 \n",
    "                     + 2 * sqrtm(sqrtm(cov_x1) @ (cov_x2.numpy()) @ (sqrtm(cov_x1))))\n",
    "\n",
    "    return W2_loss\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1217613-695f-40ac-926c-46df24c27ca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659e39de-85ed-4750-9c65-5071d8d894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.linear_or_not = True  # default is linear model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(\"number of layers should be positive!\")\n",
    "        elif num_layers == 1:\n",
    "            # Linear model\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "        else:\n",
    "            # Multi-layer model\n",
    "            self.linear_or_not = False\n",
    "            self.linears = torch.nn.ModuleList()\n",
    "            self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for layer in range(num_layers - 2):\n",
    "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "            for layer in range(num_layers - 1):\n",
    "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear_or_not:\n",
    "            # If linear model\n",
    "            return self.linear(x)\n",
    "        else:\n",
    "            # If MLP\n",
    "            h = x\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                h = self.linears[layer](h)\n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    \n",
    "                h = self.batch_norms[layer](h)\n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "\n",
    "                h = F.relu(h)\n",
    "                # h = F.relu(self.linears[layer](h))\n",
    "                \n",
    "            return self.linears[self.num_layers - 1](h)\n",
    "\n",
    "\n",
    "class MLP_generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP_generator, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.linear2 = nn.Linear(output_dim, output_dim)\n",
    "        self.linear3 = nn.Linear(output_dim, output_dim)\n",
    "        self.linear4 = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        neighbor_embedding = F.relu(self.linear(embedding))\n",
    "        neighbor_embedding = F.relu(self.linear2(neighbor_embedding))\n",
    "        neighbor_embedding = F.relu(self.linear3(neighbor_embedding))\n",
    "        neighbor_embedding = self.linear4(neighbor_embedding)\n",
    "        return neighbor_embedding\n",
    "\n",
    "\n",
    "class PairNorm(nn.Module):\n",
    "    def __init__(self, mode='PN', scale=10):\n",
    "        \n",
    "        assert mode in ['None', 'PN', 'PN-SI', 'PN-SCS']\n",
    "        super(PairNorm, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.scale = scale\n",
    "\n",
    "        # Scale can be set based on origina data, and also the current feature lengths.\n",
    "        # We leave the experiments to future. A good pool we used for choosing scale:\n",
    "        # [0.1, 1, 10, 50, 100]\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'None':\n",
    "            return x\n",
    "        col_mean = x.mean(dim=0)\n",
    "        if self.mode == 'PN':\n",
    "            x = x - col_mean\n",
    "            rownorm_mean = (1e-6 + x.pow(2).sum(dim=1).mean()).sqrt()\n",
    "            x = self.scale * x / rownorm_mean\n",
    "        if self.mode == 'PN-SI':\n",
    "            x = x - col_mean\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual\n",
    "        if self.mode == 'PN-SCS':\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual - col_mean\n",
    "        return x\n",
    "\n",
    "\n",
    "# FNN\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden, out_features, layer_num):\n",
    "        super(FNN, self).__init__()\n",
    "        self.linear1 = MLP(layer_num, in_features, hidden, out_features)\n",
    "        self.linear2 = nn.Linear(out_features, out_features)\n",
    "    def forward(self, embedding):\n",
    "        x = self.linear1(embedding)\n",
    "        x = self.linear2(F.relu(x))\n",
    "        x = F.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95d031cd-1dad-4094-a7d6-56cd9f0d9f53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GAD-NR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bddf25c-5546-4333-8798-7ad82dbddad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training\n",
    "def train(data, y, yc, ys, yj, ysj, lr, epoch, device, encoder, lambda_loss1, lambda_loss2, lambda_loss3, hidden_dim, sample_size=10,loss_step=20,\n",
    "          real_loss=False,calculate_contextual=False,calculate_structural=False):\n",
    "    '''\n",
    "     Main training function\n",
    "     INPUT:\n",
    "     -----------------------\n",
    "     data : torch geometric dataset object\n",
    "     lr    :    learning rate\n",
    "     epoch     :    number of training epoch\n",
    "     device     :   CPU or GPU\n",
    "     encoder    :    GCN or GIN or GraphSAGE\n",
    "     lambda_loss    :   Trade-off between degree loss and neighborhood reconstruction loss\n",
    "     hidden_dim     :   latent variable dimension\n",
    "    '''\n",
    "    \n",
    "    in_nodes = data.edge_index[0,:]\n",
    "    out_nodes = data.edge_index[1,:]\n",
    "    \n",
    "    \n",
    "    neighbor_dict = {}\n",
    "    for in_node, out_node in zip(in_nodes, out_nodes):\n",
    "        if in_node.item() not in neighbor_dict:\n",
    "            neighbor_dict[in_node.item()] = []\n",
    "        neighbor_dict[in_node.item()].append(out_node.item())\n",
    "\n",
    "    neighbor_num_list = []\n",
    "    for i in neighbor_dict:\n",
    "        neighbor_num_list.append(len(neighbor_dict[i]))\n",
    "    \n",
    "    neighbor_num_list = torch.tensor(neighbor_num_list).to(device)\n",
    "    \n",
    "    in_dim = data.x.shape[1]\n",
    "    GNNModel = GNNStructEncoder(in_dim, hidden_dim, hidden_dim, 2, sample_size, device=device, \n",
    "                    neighbor_num_list=neighbor_num_list, GNN_name=encoder, \n",
    "                    lambda_loss1=lambda_loss1, lambda_loss2=lambda_loss2,lambda_loss3=lambda_loss3)\n",
    "    GNNModel.to(device)\n",
    "    degree_params = list(map(id, GNNModel.degree_decoder.parameters()))\n",
    "    base_params = filter(lambda p: id(p) not in degree_params,\n",
    "                         GNNModel.parameters())\n",
    "\n",
    "    opt = torch.optim.Adam([{'params': base_params}, {'params': GNNModel.degree_decoder.parameters(), 'lr': 1e-2}],lr=lr, weight_decay=0.0003)\n",
    "    min_loss = float('inf')\n",
    "    arg_min_loss_per_node = None\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_auc_contextual = 0\n",
    "    best_auc_dense_structural = 0\n",
    "    best_auc_joint_structural = 0\n",
    "    best_auc_structure_type = 0\n",
    "    \n",
    "        \n",
    "    loss_values = []\n",
    "    for i in tqdm(range(1,epoch+1,1)):\n",
    "        \n",
    "        \n",
    "        if i%loss_step==0:\n",
    "            GNNModel.lambda_loss2 = GNNModel.lambda_loss2 + 0.5\n",
    "            GNNModel.lambda_loss3 = GNNModel.lambda_loss3 / 2\n",
    "        \n",
    "        loss,loss_per_node,h_loss,degree_loss,feature_loss = GNNModel(data.edge_index, data.x, neighbor_num_list, neighbor_dict, device=device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_per_node = loss_per_node.cpu().detach()\n",
    "        \n",
    "        h_loss = h_loss.cpu().detach()\n",
    "        degree_loss = degree_loss.cpu().detach()\n",
    "        feature_loss = feature_loss.cpu().detach()\n",
    "        \n",
    "        h_loss_norm = h_loss / (torch.max(h_loss) - torch.min(h_loss))\n",
    "        degree_loss_norm = degree_loss / (torch.max(degree_loss) - torch.min(degree_loss))\n",
    "        feature_loss_norm = feature_loss / (torch.max(feature_loss) - torch.min(feature_loss))\n",
    "        \n",
    "        comb_loss = args.h_loss_weight * h_loss_norm + args.degree_loss_weight *  degree_loss_norm + args.feature_loss_weight * feature_loss_norm\n",
    "        \n",
    "        if real_loss:\n",
    "            comp_loss = loss_per_node\n",
    "        else:\n",
    "            comp_loss = comb_loss\n",
    "            \n",
    "        \n",
    "        auc_score = eval_roc_auc(y.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score(benchmark/combined): \", auc_score)\n",
    "        \n",
    "        contextual_auc_score = eval_roc_auc(yc.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (contextual): \", contextual_auc_score)\n",
    "\n",
    "        dense_structural_auc_score = eval_roc_auc(ys.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (structural): \", dense_structural_auc_score)\n",
    "        \n",
    "        joint_type_auc_score = eval_roc_auc(yj.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (joint-type): \", joint_type_auc_score)\n",
    "        \n",
    "        structure_type_auc_score = eval_roc_auc(ysj.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (structure type): \", structure_type_auc_score) \n",
    "        \n",
    "        best_auc = max(best_auc, auc_score)\n",
    "        best_auc_contextual = max(best_auc_contextual, contextual_auc_score)\n",
    "        best_auc_dense_structural = max(best_auc_dense_structural, dense_structural_auc_score)\n",
    "        best_auc_joint_type = max(best_auc_joint_structural, joint_type_auc_score)\n",
    "        best_auc_structure_type = max(best_auc_structure_type, structure_type_auc_score)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"===========================================================================================\")\n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score(benchmark/combined): \", best_auc)\n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (contextual): \", best_auc_contextual)\n",
    "\n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (structural): \", best_auc_dense_structural)\n",
    "        \n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (joint-type): \", best_auc_joint_type)\n",
    "        \n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (structure type): \", best_auc_structure_type) \n",
    "        print(\"===========================================================================================\")\n",
    "        \n",
    "        \n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            arg_min_loss_per_node = loss_per_node\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss.cpu().detach()\n",
    "        loss_values.append(loss)\n",
    "        \n",
    "        \n",
    "        if args.plot_loss:\n",
    "\n",
    "            plt.plot(np.array(loss_values), 'r')\n",
    "            plt.show()\n",
    "    \n",
    "    return min_loss.item(), arg_min_loss_per_node.cpu().detach()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, embeddings, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(embeddings)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "def train_real_datasets(dataset_str, epoch_num = 10, lr = 5e-6, encoder = \"GCN\", \n",
    "                        lambda_loss1=1e-2, lambda_loss2=1e-3, lambda_loss3=1e-3, sample_size=8, loss_step=20, hidden_dim=None,\n",
    "                        real_loss=False,calculate_contextual=False,calculate_structural=False):\n",
    "    \n",
    "    data = load_data(dataset_str)\n",
    "    node_features = data.x\n",
    "    \n",
    "    if args.normalize_feat:\n",
    "    \n",
    "        node_features_min = node_features.min()\n",
    "        node_features_max = node_features.max()\n",
    "        node_features = (node_features - node_features_min)/node_features_max\n",
    "        data.x = node_features\n",
    "    \n",
    "    yc = []\n",
    "    ys = []\n",
    "    yj = []\n",
    "    \n",
    "    if calculate_contextual:\n",
    "        \n",
    "        if dataset_str == \"inj_cora\":\n",
    "            yc = data.y >> 0 & 1 # contextual outliers\n",
    "        else:\n",
    "            data, yc = gen_contextual_outliers(data=data,n=args.contextual_n,k=args.contextual_k)\n",
    "            \n",
    "        yc = yc.cpu().detach()\n",
    "    \n",
    "    \n",
    "    if calculate_structural:\n",
    "        \n",
    "        if dataset_str == \"inj_cora\":\n",
    "            ys = data.y >> 1 & 1 # structural outliers\n",
    "        else:\n",
    "            data, ys = gen_structural_outliers(data=data,n=args.structural_n,m=args.structural_m,p=0.2)\n",
    "            \n",
    "        ys = ys.cpu().detach()\n",
    "        data, yj = gen_joint_structural_outliers(data=data,n=args.structural_n,m=args.structural_m)\n",
    "        \n",
    "    \n",
    "    if args.use_combine_outlier:\n",
    "        data.y = torch.logical_or(ys, yc).int()\n",
    "        \n",
    "    ysj = torch.logical_or(ys, yj).int()\n",
    "    y = data.y.bool()    # binary labels (inlier/outlier)\n",
    "    y = y.cpu().detach()\n",
    "    \n",
    "    edge_index = data.edge_index.cpu()\n",
    "    \n",
    "    num_nodes = node_features.shape[0]\n",
    "    self_edges = torch.tensor([[i for i in range(num_nodes)],[i for i in range(num_nodes)]])\n",
    "    edge_index = torch.cat([edge_index,self_edges],dim=1)\n",
    "    data.edge_index = edge_index\n",
    "    data = data.to(device)\n",
    "    \n",
    "\n",
    "    loss, loss_per_node, = train(data, y, yc, ys, yj, ysj, lr=lr, epoch=epoch_num, device=device, encoder=encoder, lambda_loss1=lambda_loss1, \n",
    "          lambda_loss2=lambda_loss2, lambda_loss3=lambda_loss3, hidden_dim=hidden_dim, sample_size=sample_size,loss_step=loss_step,\n",
    "                                 real_loss=real_loss,calculate_contextual=calculate_contextual,calculate_structural=calculate_structural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a718ab-e1e0-49be-9748-dc4e8e0af644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ground truth neighbors Hv\n",
    "def generate_gt_neighbor(neighbor_dict, node_embeddings, neighbor_num_list, in_dim):\n",
    "    max_neighbor_num = max(neighbor_num_list)\n",
    "    all_gt_neighbor_embeddings = []\n",
    "    for i, embedding in enumerate(node_embeddings):\n",
    "        neighbor_indexes = neighbor_dict[i]\n",
    "        neighbor_embeddings = []\n",
    "        for index in neighbor_indexes:\n",
    "            neighbor_embeddings.append(node_embeddings[index].tolist())\n",
    "        if len(neighbor_embeddings) < max_neighbor_num:\n",
    "            for _ in range(max_neighbor_num - len(neighbor_embeddings)):\n",
    "                neighbor_embeddings.append(torch.zeros(in_dim).tolist())\n",
    "        all_gt_neighbor_embeddings.append(neighbor_embeddings)\n",
    "    return all_gt_neighbor_embeddings\n",
    "\n",
    "\n",
    "# Main Autoencoder structure here\n",
    "class GNNStructEncoder(nn.Module):\n",
    "    def __init__(self, in_dim0, in_dim, hidden_dim, layer_num, sample_size, device, neighbor_num_list, \n",
    "                 GNN_name=\"GIN\", norm_mode=\"PN-SCS\", norm_scale=20, lambda_loss1=0.01, lambda_loss2=0.001, lambda_loss3=0.0001):\n",
    "        \n",
    "        super(GNNStructEncoder, self).__init__()\n",
    "        \n",
    "        self.mlp0 = nn.Linear(in_dim0, hidden_dim)\n",
    "        self.norm = PairNorm(norm_mode, norm_scale)\n",
    "        self.out_dim = hidden_dim\n",
    "        self.lambda_loss1 = lambda_loss1\n",
    "        self.lambda_loss2 = lambda_loss2\n",
    "        self.lambda_loss3 = lambda_loss3\n",
    "        # GNN Encoder\n",
    "        if GNN_name == \"GIN\":\n",
    "            self.linear1 = MLP(layer_num, hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.graphconv1 = GINConv(self.linear1)\n",
    "            self.linear2 = MLP(layer_num, hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GINConv(self.linear2)\n",
    "        elif GNN_name == \"GCN\":\n",
    "            self.graphconv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        elif GNN_name == \"GAT\":\n",
    "            self.graphconv1 = GATConv(hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GATConv(hidden_dim, hidden_dim)\n",
    "        else:\n",
    "            self.graphconv1 = SAGEConv(hidden_dim, hidden_dim, aggr='sum')\n",
    "            # self.graphconv2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "            \n",
    "            # self.graphconv1 = GraphSAGE(hidden_dim, hidden_dim, aggr='mean', num_layers=1)\n",
    "            \n",
    "\n",
    "        self.neighbor_num_list = neighbor_num_list\n",
    "        self.tot_node = len(neighbor_num_list)\n",
    "\n",
    "        self.gaussian_mean = nn.Parameter(\n",
    "            torch.FloatTensor(sample_size, hidden_dim).uniform_(-0.5 / hidden_dim,\n",
    "                                                                                     0.5 / hidden_dim)).to(device)\n",
    "        self.gaussian_log_sigma = nn.Parameter(\n",
    "            torch.FloatTensor(sample_size, hidden_dim).uniform_(-0.5 / hidden_dim,\n",
    "                                                                                     0.5 / hidden_dim)).to(device)\n",
    "        self.m = torch.distributions.Normal(torch.zeros(sample_size, hidden_dim),\n",
    "                                            torch.ones(sample_size, hidden_dim))\n",
    "        \n",
    "        self.m_batched = torch.distributions.Normal(torch.zeros(sample_size, self.tot_node, hidden_dim),\n",
    "                                            torch.ones(sample_size, self.tot_node, hidden_dim))\n",
    "\n",
    "        self.m_h = torch.distributions.Normal(torch.zeros(sample_size, hidden_dim),\n",
    "                                            50* torch.ones(sample_size, hidden_dim))\n",
    "\n",
    "        # Before MLP Gaussian Means, and std\n",
    "\n",
    "        self.mlp_gaussian_mean = nn.Parameter(\n",
    "            torch.FloatTensor(hidden_dim).uniform_(-0.5 / hidden_dim, 0.5 / hidden_dim)).to(device)\n",
    "        self.mlp_gaussian_log_sigma = nn.Parameter(\n",
    "            torch.FloatTensor(hidden_dim).uniform_(-0.5 / hidden_dim, 0.5 / hidden_dim)).to(device)\n",
    "        self.mlp_m = torch.distributions.Normal(torch.zeros(hidden_dim), torch.ones(hidden_dim))\n",
    "\n",
    "        self.mlp_mean = FNN(hidden_dim, hidden_dim, hidden_dim, 3)\n",
    "        self.mlp_sigma = FNN(hidden_dim, hidden_dim, hidden_dim, 3)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "        self.mean_agg = SAGEConv(hidden_dim, hidden_dim, aggr='mean', normalize = False)\n",
    "        # self.mean_agg = GraphSAGE(hidden_dim, hidden_dim, aggr='mean', num_layers=1)\n",
    "        self.std_agg = PNAConv(hidden_dim, hidden_dim, aggregators=[\"std\"],scalers=[\"identity\"], deg=neighbor_num_list)        \n",
    "        self.layer1_generator = MLP_generator(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Decoders\n",
    "        self.degree_decoder = FNN(hidden_dim, hidden_dim, 1, 4)\n",
    "        self.feature_decoder = FNN(hidden_dim, hidden_dim, in_dim, 3)\n",
    "        self.degree_loss_func = nn.MSELoss()\n",
    "        self.feature_loss_func = nn.MSELoss()\n",
    "        self.pool = mp.Pool(4)\n",
    "        self.in_dim = in_dim\n",
    "        self.sample_size = sample_size \n",
    "        self.init_projection = FNN(in_dim, hidden_dim, hidden_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward_encoder(self, x, edge_index):\n",
    "        \n",
    "        # Apply graph convolution and activation, pair-norm to avoid trivial solution\n",
    "        h0 = self.mlp0(x)\n",
    "        l1 = self.graphconv1(h0, edge_index)\n",
    "        return l1, h0\n",
    "        \n",
    "        \n",
    "\n",
    "    # Sample neighbors from neighbor set, if the length of neighbor set less than sample size, then do the padding.\n",
    "    def sample_neighbors(self, indexes, neighbor_dict, gt_embeddings):\n",
    "        sampled_embeddings_list = []\n",
    "        mark_len_list = []\n",
    "        for index in indexes:\n",
    "            sampled_embeddings = []\n",
    "            neighbor_indexes = neighbor_dict[index]\n",
    "            if len(neighbor_indexes) < self.sample_size:\n",
    "                mask_len = len(neighbor_indexes)\n",
    "                sample_indexes = neighbor_indexes\n",
    "            else:\n",
    "                sample_indexes = random.sample(neighbor_indexes, self.sample_size)\n",
    "                mask_len = self.sample_size\n",
    "            for index in sample_indexes:\n",
    "                sampled_embeddings.append(gt_embeddings[index].tolist())\n",
    "            if len(sampled_embeddings) < self.sample_size:\n",
    "                for _ in range(self.sample_size - len(sampled_embeddings)):\n",
    "                    sampled_embeddings.append(torch.zeros(self.out_dim).tolist())\n",
    "            sampled_embeddings_list.append(sampled_embeddings)\n",
    "            mark_len_list.append(mask_len)\n",
    "        \n",
    "        return sampled_embeddings_list, mark_len_list\n",
    "    \n",
    "    def reconstruction_neighbors2(self, l1, h0, edge_index):\n",
    "                \n",
    "        recon_loss = 0\n",
    "        recon_loss_per_node = []\n",
    "    \n",
    "        sample_sz_per_node = [self.sample_size]* self.tot_node\n",
    "\n",
    "        # mean_neigh = self.graphconv1(h0, edge_index)\n",
    "        mean_neigh = self.mean_agg(h0, edge_index).detach()\n",
    "        std_neigh = self.std_agg(h0, edge_index).detach()\n",
    "        # mean_neigh = self.graphconv2(mean_neigh, edge_index)\n",
    "        # mean_neigh = l1\n",
    "        # mean_neigh = self.mean_agg(h0, edge_index, num_sampled_nodes_per_hop=sample_sz_per_node)\n",
    "        \n",
    "        \n",
    "        cov_neigh = torch.bmm(std_neigh.unsqueeze(dim=-1),std_neigh.unsqueeze(dim=1))\n",
    "        \n",
    "        target_mean = mean_neigh\n",
    "        target_cov = cov_neigh\n",
    "        \n",
    "        self_embedding = l1\n",
    "        # self_embedding = _normalize(self_embedding)\n",
    "        \n",
    "        self_embedding = self_embedding.unsqueeze(0)\n",
    "        self_embedding = self_embedding.repeat(self.sample_size, 1, 1)\n",
    "        generated_mean = self.mlp_mean(self_embedding)\n",
    "        generated_sigma = self.mlp_sigma(self_embedding)\n",
    "\n",
    "        \n",
    "        std_z = self.m_batched.sample().to(device)\n",
    "        var = generated_mean + generated_sigma.exp() * std_z\n",
    "        nhij = self.layer1_generator(var)\n",
    "        \n",
    "        generated_mean = torch.mean(nhij,dim=0)\n",
    "        generated_std = torch.std(nhij,dim=0)\n",
    "        generated_cov = torch.bmm(generated_std.unsqueeze(dim=-1),generated_std.unsqueeze(dim=1))/self.sample_size\n",
    "        \n",
    "        \n",
    "        tot_nodes = l1.shape[0]\n",
    "        h_dim = l1.shape[1]\n",
    "        \n",
    "        single_eye = torch.eye(h_dim).to(device)\n",
    "        single_eye = single_eye.unsqueeze(dim=0)\n",
    "        batch_eye = single_eye.repeat(tot_nodes,1,1)\n",
    "        \n",
    "        target_cov = target_cov + batch_eye\n",
    "        generated_cov = generated_cov + batch_eye\n",
    "\n",
    "        \n",
    "        det_target_cov = torch.linalg.det(target_cov) \n",
    "        det_generated_cov = torch.linalg.det(generated_cov) \n",
    "        trace_mat = torch.matmul(torch.inverse(generated_cov),target_cov)\n",
    "             \n",
    "        \n",
    "        x = torch.bmm(torch.unsqueeze(generated_mean - target_mean,dim=1),torch.inverse(generated_cov))\n",
    "        y = torch.unsqueeze(generated_mean - target_mean,dim=-1)\n",
    "        z = torch.bmm(x,y).squeeze()\n",
    "        \n",
    "        KL_loss = 0.5 * (torch.log(det_target_cov / det_generated_cov) - h_dim  + trace_mat.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1) + z)\n",
    "        \n",
    "        recon_loss = torch.mean(KL_loss)\n",
    "        recon_loss_per_node = KL_loss\n",
    "        \n",
    "        \n",
    "        return recon_loss, recon_loss_per_node\n",
    "    \n",
    "                \n",
    "        # self_embedding_min = self_embedding.min()\n",
    "        # self_embedding_max = self_embedding.max()\n",
    "        # self_embedding = (self_embedding - self_embedding_min)/(self_embedding_max+1e-14)\n",
    "        # generated_mean = self.mean_generator(self_embedding)\n",
    "        # generated_mean = _normalize(generated_mean)\n",
    "        # generated_std = self.std_generator(self_embedding)\n",
    "        # generated_std = _normalize(generated_std)\n",
    "        # generated_std = generated_std.abs().squeeze()\n",
    "        # generated_std = self.softplus(generated_std)\n",
    "        # generated_std = generated_std.exp().squeeze()\n",
    "        \n",
    "        # cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / max((nn-1),1)\n",
    "        # cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / max((nn-1),1)\n",
    "        \n",
    "        # generated_cov = generated_cov + torch.rand(generated_cov.shape).to(device)\n",
    "        # generated_cov = generated_cov * batch_eye\n",
    "        \n",
    "        # print(torch.isfinite(det_target_cov).all())\n",
    "        # print(torch.isfinite(det_generated_cov).all()) \n",
    "        \n",
    "        # KL_loss = 0.5 * (math.log(torch.det(cov_x1) / torch.det(cov_x2)) - h_dim  + torch.trace(torch.inverse(cov_x2).matmul(cov_x1)) \n",
    "        #     + (mean_x2 - mean_x1).reshape(1,-1).matmul(torch.inverse(cov_x2)).matmul(mean_x2 - mean_x1))\n",
    "    \n",
    "\n",
    "    def reconstruction_neighbors(self, FNN_generator, neighbor_indexes, neighbor_dict, from_layer, to_layer, device):\n",
    "        \n",
    "        \n",
    "        local_index_loss = 0\n",
    "        local_index_loss_per_node = []\n",
    "        sampled_embeddings_list, mark_len_list = self.sample_neighbors(neighbor_indexes, neighbor_dict, to_layer)\n",
    "        for i, neighbor_embeddings1 in enumerate(sampled_embeddings_list):\n",
    "            # Generating h^k_v, reparameterization trick\n",
    "            \n",
    "            # print(len(neighbor_embeddings1))\n",
    "            \n",
    "            index = neighbor_indexes[i]\n",
    "            mask_len1 = mark_len_list[i]\n",
    "            mean = from_layer[index].repeat(self.sample_size, 1)\n",
    "            mean = self.mlp_mean(mean)\n",
    "            sigma = from_layer[index].repeat(self.sample_size, 1)\n",
    "            sigma = self.mlp_sigma(sigma)\n",
    "            std_z = self.m.sample().to(device)\n",
    "            var = mean + sigma.exp() * std_z\n",
    "            nhij = FNN_generator(var)\n",
    "            \n",
    "            generated_neighbors = nhij\n",
    "            sum_neighbor_norm = 0\n",
    "            \n",
    "            for indexi, generated_neighbor in enumerate(generated_neighbors):\n",
    "                sum_neighbor_norm += torch.norm(generated_neighbor) / math.sqrt(self.out_dim)\n",
    "            generated_neighbors = torch.unsqueeze(generated_neighbors, dim=0).to(device)\n",
    "            target_neighbors = torch.unsqueeze(torch.FloatTensor(neighbor_embeddings1), dim=0).to(device)\n",
    "            \n",
    "            if args.neigh_loss == \"KL\":\n",
    "                KL_loss = KL_neighbor_loss(generated_neighbors, target_neighbors, mask_len1)\n",
    "                local_index_loss += KL_loss\n",
    "                local_index_loss_per_node.append(KL_loss)\n",
    "            \n",
    "            else:\n",
    "                W2_loss = W2_neighbor_loss(generated_neighbors, target_neighbors, mask_len1)\n",
    "                local_index_loss += W2_loss\n",
    "                local_index_loss_per_node.append(W2_loss)\n",
    "            \n",
    "            \n",
    "        local_index_loss_per_node = torch.stack(local_index_loss_per_node)\n",
    "        return local_index_loss, local_index_loss_per_node\n",
    "    \n",
    "\n",
    "    def neighbor_decoder(self, gij, ground_truth_degree_matrix, h0, neighbor_dict, device, h, edge_index):\n",
    "        \n",
    "        # Degree decoder below:\n",
    "        tot_nodes = gij.shape[0]\n",
    "        degree_logits = self.degree_decoding(gij)\n",
    "        ground_truth_degree_matrix = torch.unsqueeze(ground_truth_degree_matrix, dim=1)\n",
    "        degree_loss = self.degree_loss_func(degree_logits, ground_truth_degree_matrix.float())\n",
    "        degree_loss_per_node = (degree_logits-ground_truth_degree_matrix).pow(2)\n",
    "        _, degree_masks = torch.max(degree_logits.data, dim=1)\n",
    "        h_loss = 0\n",
    "        feature_loss = 0\n",
    "        # layer 1\n",
    "        loss_list = []\n",
    "        loss_list_per_node = []\n",
    "        feature_loss_list = []\n",
    "        # Sample multiple times to remove noise\n",
    "        for _ in range(3):\n",
    "            local_index_loss_sum = 0\n",
    "            local_index_loss_sum_per_node = []\n",
    "            indexes = []\n",
    "            h0_prime = self.feature_decoder(gij)\n",
    "            feature_losses = self.feature_loss_func(h0, h0_prime)\n",
    "            feature_losses_per_node = (h0-h0_prime).pow(2).mean(1)\n",
    "            feature_loss_list.append(feature_losses_per_node)\n",
    "            \n",
    "\n",
    "            \n",
    "            # local_index_loss, local_index_loss_per_node = self.reconstruction_neighbors(self.layer1_generator, indexes, neighbor_dict, gij, h0, device)\n",
    "            local_index_loss, local_index_loss_per_node = self.reconstruction_neighbors2(gij,h0,edge_index)\n",
    "            \n",
    "            # print(local_index_loss, local_index_loss2)\n",
    "            # print(local_index_loss_per_node, local_index_loss_per_node2)\n",
    "\n",
    "            loss_list.append(local_index_loss)\n",
    "            loss_list_per_node.append(local_index_loss_per_node)\n",
    "            \n",
    "        loss_list = torch.stack(loss_list)\n",
    "        h_loss += torch.mean(loss_list)\n",
    "        \n",
    "        loss_list_per_node = torch.stack(loss_list_per_node)\n",
    "        h_loss_per_node = torch.mean(loss_list_per_node,dim=0)\n",
    "        \n",
    "        feature_loss_per_node = torch.mean(torch.stack(feature_loss_list),dim=0)\n",
    "        feature_loss += torch.mean(torch.stack(feature_loss_list))\n",
    "                \n",
    "        h_loss_per_node = h_loss_per_node.reshape(tot_nodes,1)\n",
    "        degree_loss_per_node = degree_loss_per_node.reshape(tot_nodes,1)\n",
    "        feature_loss_per_node = feature_loss_per_node.reshape(tot_nodes,1)\n",
    "        \n",
    "        loss = self.lambda_loss1 * h_loss + degree_loss * self.lambda_loss3 + self.lambda_loss2 * feature_loss\n",
    "        loss_per_node = self.lambda_loss1 * h_loss_per_node + degree_loss_per_node * self.lambda_loss3 + self.lambda_loss2 * feature_loss_per_node\n",
    "        \n",
    "\n",
    "        return loss,loss_per_node,h_loss_per_node,degree_loss_per_node,feature_loss_per_node\n",
    "\n",
    "    def degree_decoding(self, node_embeddings):\n",
    "        degree_logits = F.relu(self.degree_decoder(node_embeddings))\n",
    "        return degree_logits\n",
    "\n",
    "    def forward(self, edge_index, x, ground_truth_degree_matrix, neighbor_dict, device):\n",
    "        \n",
    "        # Generate GNN encodings\n",
    "        l1, h0 = self.forward_encoder(x, edge_index)\n",
    "        loss, loss_per_node,h_loss,degree_loss,feature_loss = self.neighbor_decoder(l1, ground_truth_degree_matrix, h0, neighbor_dict, device, x, edge_index)\n",
    "        \n",
    "        return loss, loss_per_node,h_loss,degree_loss,feature_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be33ad17-0dda-4225-a900-85f33f6680d1",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86955e8-54b2-4103-974d-98fff445534c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "parser = argparse.ArgumentParser(description='parameters')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--dataset', type=str, default=\"inj_cora\")\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--epoch_num', type=int, default=500)\n",
    "parser.add_argument('--lambda_loss1', type=float, default=1e-2) #neighbor reconstruction loss weight\n",
    "parser.add_argument('--lambda_loss2', type=float, default=0.1) #feature loss weight\n",
    "parser.add_argument('--lambda_loss3', type=float, default=0.8) #degree loss weight\n",
    "parser.add_argument('--sample_size', type=int, default=10)\n",
    "parser.add_argument('--dimension', type=int, default=128)\n",
    "parser.add_argument('--encoder', type=str, default=\"GCN\")\n",
    "parser.add_argument('--loss_step', type=int, default=5000)\n",
    "parser.add_argument('--real_loss', type=bool, default=False) #use real loss or adaptive loss\n",
    "parser.add_argument('--neigh_loss', type=str, default=\"KL\")\n",
    "parser.add_argument('--h_loss_weight', type=float, default=1.0)#adaptive loss weight for h_loss\n",
    "parser.add_argument('--feature_loss_weight', type=float, default=2.5) #adaptive loss weight for feature loss\n",
    "parser.add_argument('--degree_loss_weight', type=float, default=0)#adaptive loss weight for degree loss\n",
    "parser.add_argument('--calculate_contextual', type=bool, default=True)\n",
    "parser.add_argument('--contextual_n', type=int, default=70)\n",
    "parser.add_argument('--contextual_k', type=int, default=10)\n",
    "parser.add_argument('--calculate_structural', type=bool, default=True)\n",
    "parser.add_argument('--structural_n', type=int, default=70)\n",
    "parser.add_argument('--structural_m', type=int, default=10)\n",
    "parser.add_argument('--use_combine_outlier', type=bool, default=False)\n",
    "parser.add_argument('--plot_loss', type=bool, default=True)\n",
    "parser.add_argument('--normalize_feat', type=bool, default=False)\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction\")\n",
    "print(\"Dataset: \", args.dataset, \"lr:\", args.lr, \"lambda_loss1 (neighbor):\",args.lambda_loss1, \"lambda_loss2 (feature):\", args.lambda_loss2, \"lambda_loss3 (degree):\", args.lambda_loss3, \"sample_size:\", args.sample_size, \"dimension:\",args.dimension, \"encoder:\", args.encoder, \"loss_step:\", args.loss_step,\"real_loss:\", args.real_loss, \"h_loss_weight:\",args.h_loss_weight,\"feature_loss_weight\",args.feature_loss_weight,\"degree_loss_weight:\",args.degree_loss_weight,\n",
    "\"calculate_contextual\",args.calculate_contextual,\"calculate_structural\",args.calculate_structural)\n",
    "\n",
    "\n",
    "dataset_str = args.dataset\n",
    "train_real_datasets(dataset_str=dataset_str, lr=args.lr, epoch_num=args.epoch_num, lambda_loss1=args.lambda_loss1, \n",
    "lambda_loss2=args.lambda_loss2, lambda_loss3=args.lambda_loss3, encoder=args.encoder, sample_size=args.sample_size, loss_step=args.loss_step, \n",
    "hidden_dim=args.dimension,real_loss=args.real_loss,calculate_contextual=args.calculate_contextual,calculate_structural=args.calculate_structural)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NWRGAE",
   "language": "python",
   "name": "nwrgae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
