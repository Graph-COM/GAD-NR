{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5727f30e-6d72-4ff1-b47c-20e13af635ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277cb61f-9894-42a6-b3e7-f62b3265dc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy206/.conda/envs/cent7/2020.11-py38/NWRGAE/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import seaborn as sb\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import statistics\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "from dgl.data import CitationGraphDataset\n",
    "# from dgl.nn import GINConv, GraphConv, SAGEConv\n",
    "import seaborn as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn as sk\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch_geometric.nn import GCNConv,GINConv,SAGEConv,GATConv,PNAConv, GraphSAGE\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.transforms import normalize_features\n",
    "from pygod.utils import load_data\n",
    "from pygod.utils.utility import check_parameter\n",
    "from pygod.metrics import eval_roc_auc\n",
    "from pygod.generator import gen_contextual_outliers, gen_structural_outliers\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8a0f6-41cb-4b22-9192-418310bf8923",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a1f108-b244-4fed-92da-07a65c574a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _normalize(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x_norm = (x - x_min)/x_max\n",
    "    return x_norm\n",
    "\n",
    "def gen_joint_structural_outliers(data, m, n, random_state=None):\n",
    "    \"\"\"\n",
    "    We randomly select n nodes from the network which will be the anomalies \n",
    "    and for each node we select m nodes from the network. \n",
    "    We connect each of n nodes with the m other nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : PyTorch Geometric Data instance (torch_geometric.data.Data)\n",
    "        The input data.\n",
    "    m : int\n",
    "        Number nodes in the outlier cliques.\n",
    "    n : int\n",
    "        Number of outlier cliques.\n",
    "    p : int, optional\n",
    "        Probability of edge drop in cliques. Default: ``0``.\n",
    "    random_state : int, optional\n",
    "        The seed to control the randomness, Default: ``None``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : PyTorch Geometric Data instance (torch_geometric.data.Data)\n",
    "        The structural outlier graph with injected edges.\n",
    "    y_outlier : torch.Tensor\n",
    "        The outlier label tensor where 1 represents outliers and 0 represents\n",
    "        regular nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, Data):\n",
    "        raise TypeError(\"data should be torch_geometric.data.Data\")\n",
    "\n",
    "    if isinstance(m, int):\n",
    "        check_parameter(m, low=0, high=data.num_nodes, param_name='m')\n",
    "    else:\n",
    "        raise ValueError(\"m should be int, got %s\" % m)\n",
    "\n",
    "    if isinstance(n, int):\n",
    "        check_parameter(n, low=0, high=data.num_nodes, param_name='n')\n",
    "    else:\n",
    "        raise ValueError(\"n should be int, got %s\" % n)\n",
    "\n",
    "    check_parameter(m * n, low=0, high=data.num_nodes, param_name='m*n')\n",
    "\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "\n",
    "    outlier_idx = np.random.choice(data.num_nodes, size=n, replace=False)\n",
    "    all_nodes = [i for i in range(data.num_nodes)]\n",
    "    rem_nodes = []\n",
    "    \n",
    "    for node in all_nodes:\n",
    "        if node is not outlier_idx:\n",
    "            rem_nodes.append(node)\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_edges = []\n",
    "    \n",
    "    # connect all m nodes in each clique\n",
    "    for i in range(0, n):\n",
    "        other_idx = np.random.choice(data.num_nodes, size=m, replace=False)\n",
    "        for j in other_idx:\n",
    "            new_edges.append(torch.tensor([[i, j]], dtype=torch.long))\n",
    "                    \n",
    "\n",
    "    new_edges = torch.cat(new_edges)\n",
    "\n",
    "\n",
    "    y_outlier = torch.zeros(data.x.shape[0], dtype=torch.long)\n",
    "    y_outlier[outlier_idx] = 1\n",
    "\n",
    "    data.edge_index = torch.cat([data.edge_index, new_edges.T], dim=1)\n",
    "\n",
    "    return data, y_outlier\n",
    "\n",
    "\n",
    "def KL_neighbor_loss(predictions, targets, mask_len):\n",
    "    x1 = predictions.squeeze().cpu().detach()\n",
    "    x2 = targets.squeeze().cpu().detach()\n",
    "    \n",
    "    mean_x1 = x1.mean(0)\n",
    "    mean_x2 = x2.mean(0)\n",
    "    \n",
    "    nn = x1.shape[0]\n",
    "    h_dim = x1.shape[1]\n",
    "    \n",
    "    cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / max((nn-1),1)\n",
    "    cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / max((nn-1),1)\n",
    "    \n",
    "    eye = torch.eye(h_dim)\n",
    "    cov_x1 = cov_x1 + eye\n",
    "    cov_x2 = cov_x2 + eye\n",
    "    \n",
    "    KL_loss = 0.5 * (math.log(torch.det(cov_x1) / torch.det(cov_x2)) - h_dim  + torch.trace(torch.inverse(cov_x2).matmul(cov_x1)) \n",
    "            + (mean_x2 - mean_x1).reshape(1,-1).matmul(torch.inverse(cov_x2)).matmul(mean_x2 - mean_x1))\n",
    "    KL_loss = KL_loss.to(device)\n",
    "    return KL_loss\n",
    "\n",
    "def W2_neighbor_loss(predictions, targets, mask_len):\n",
    "    \n",
    "    x1 = predictions.squeeze().cpu().detach()\n",
    "    x2 = targets.squeeze().cpu().detach()\n",
    "    \n",
    "    mean_x1 = x1.mean(0)\n",
    "    mean_x2 = x2.mean(0)\n",
    "\n",
    "    nn = x1.shape[0]\n",
    "    \n",
    "    cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / (nn-1)\n",
    "    cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / (nn-1)\n",
    "    \n",
    "\n",
    "    W2_loss = torch.square(mean_x1-mean_x2).sum() + torch.trace(cov_x1 + cov_x2 \n",
    "                     + 2 * sqrtm(sqrtm(cov_x1) @ (cov_x2.numpy()) @ (sqrtm(cov_x1))))\n",
    "\n",
    "    return W2_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1217613-695f-40ac-926c-46df24c27ca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659e39de-85ed-4750-9c65-5071d8d894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.linear_or_not = True  # default is linear model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(\"number of layers should be positive!\")\n",
    "        elif num_layers == 1:\n",
    "            # Linear model\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "        else:\n",
    "            # Multi-layer model\n",
    "            self.linear_or_not = False\n",
    "            self.linears = torch.nn.ModuleList()\n",
    "            self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for layer in range(num_layers - 2):\n",
    "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "            for layer in range(num_layers - 1):\n",
    "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear_or_not:\n",
    "            # If linear model\n",
    "            return self.linear(x)\n",
    "        else:\n",
    "            # If MLP\n",
    "            h = x\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                h = self.linears[layer](h)\n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    \n",
    "                h = self.batch_norms[layer](h)\n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "\n",
    "                h = F.relu(h)\n",
    "                # h = F.relu(self.linears[layer](h))\n",
    "                \n",
    "            return self.linears[self.num_layers - 1](h)\n",
    "\n",
    "\n",
    "class MLP_generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP_generator, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.linear2 = nn.Linear(output_dim, output_dim)\n",
    "        self.linear3 = nn.Linear(output_dim, output_dim)\n",
    "        self.linear4 = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        neighbor_embedding = F.relu(self.linear(embedding))\n",
    "        neighbor_embedding = F.relu(self.linear2(neighbor_embedding))\n",
    "        neighbor_embedding = F.relu(self.linear3(neighbor_embedding))\n",
    "        neighbor_embedding = self.linear4(neighbor_embedding)\n",
    "        return neighbor_embedding\n",
    "\n",
    "\n",
    "class PairNorm(nn.Module):\n",
    "    def __init__(self, mode='PN', scale=10):\n",
    "        \n",
    "        assert mode in ['None', 'PN', 'PN-SI', 'PN-SCS']\n",
    "        super(PairNorm, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.scale = scale\n",
    "\n",
    "        # Scale can be set based on origina data, and also the current feature lengths.\n",
    "        # We leave the experiments to future. A good pool we used for choosing scale:\n",
    "        # [0.1, 1, 10, 50, 100]\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'None':\n",
    "            return x\n",
    "        col_mean = x.mean(dim=0)\n",
    "        if self.mode == 'PN':\n",
    "            x = x - col_mean\n",
    "            rownorm_mean = (1e-6 + x.pow(2).sum(dim=1).mean()).sqrt()\n",
    "            x = self.scale * x / rownorm_mean\n",
    "        if self.mode == 'PN-SI':\n",
    "            x = x - col_mean\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual\n",
    "        if self.mode == 'PN-SCS':\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual - col_mean\n",
    "        return x\n",
    "\n",
    "\n",
    "# FNN\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden, out_features, layer_num):\n",
    "        super(FNN, self).__init__()\n",
    "        self.linear1 = MLP(layer_num, in_features, hidden, out_features)\n",
    "        self.linear2 = nn.Linear(out_features, out_features)\n",
    "    def forward(self, embedding):\n",
    "        x = self.linear1(embedding)\n",
    "        x = self.linear2(F.relu(x))\n",
    "        x = F.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d031cd-1dad-4094-a7d6-56cd9f0d9f53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GAD-NR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bddf25c-5546-4333-8798-7ad82dbddad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "/tmp/ipykernel_32771/3078169842.py:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Required Time: \" (en-st)*1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "def train(data, y, yc, ys, yj, ysj, lr, epoch, device, encoder, lambda_loss1, lambda_loss2, lambda_loss3, hidden_dim, sample_size=10,loss_step=20,\n",
    "          real_loss=False,calculate_contextual=False,calculate_structural=False):\n",
    "    '''\n",
    "     Main training function\n",
    "     INPUT:\n",
    "     -----------------------\n",
    "     data : torch geometric dataset object\n",
    "     lr    :    learning rate\n",
    "     epoch     :    number of training epoch\n",
    "     device     :   CPU or GPU\n",
    "     encoder    :    GCN or GIN or GraphSAGE\n",
    "     lambda_loss    :   Trade-off between degree loss and neighborhood reconstruction loss\n",
    "     hidden_dim     :   latent variable dimension\n",
    "    '''\n",
    "    \n",
    "    in_nodes = data.edge_index[0,:]\n",
    "    out_nodes = data.edge_index[1,:]\n",
    "    \n",
    "    \n",
    "    neighbor_dict = {}\n",
    "    for in_node, out_node in zip(in_nodes, out_nodes):\n",
    "        if in_node.item() not in neighbor_dict:\n",
    "            neighbor_dict[in_node.item()] = []\n",
    "        neighbor_dict[in_node.item()].append(out_node.item())\n",
    "\n",
    "    neighbor_num_list = []\n",
    "    for i in neighbor_dict:\n",
    "        neighbor_num_list.append(len(neighbor_dict[i]))\n",
    "    \n",
    "    neighbor_num_list = torch.tensor(neighbor_num_list).to(device)\n",
    "    \n",
    "    in_dim = data.x.shape[1]\n",
    "    GNNModel = GNNStructEncoder(in_dim, hidden_dim, hidden_dim, 2, sample_size, device=device, \n",
    "                    neighbor_num_list=neighbor_num_list, GNN_name=encoder, \n",
    "                    lambda_loss1=lambda_loss1, lambda_loss2=lambda_loss2,lambda_loss3=lambda_loss3)\n",
    "    GNNModel.to(device)\n",
    "    degree_params = list(map(id, GNNModel.degree_decoder.parameters()))\n",
    "    base_params = filter(lambda p: id(p) not in degree_params,\n",
    "                         GNNModel.parameters())\n",
    "\n",
    "    opt = torch.optim.Adam([{'params': base_params}, {'params': GNNModel.degree_decoder.parameters(), 'lr': 1e-2}],lr=lr, weight_decay=0.0003)\n",
    "    min_loss = float('inf')\n",
    "    arg_min_loss_per_node = None\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_auc_contextual = 0\n",
    "    best_auc_dense_structural = 0\n",
    "    best_auc_joint_structural = 0\n",
    "    best_auc_structure_type = 0\n",
    "    \n",
    "        \n",
    "    loss_values = []\n",
    "    for i in tqdm(range(1,epoch+1,1)):\n",
    "        \n",
    "        \n",
    "        if i%loss_step==0:\n",
    "            GNNModel.lambda_loss2 = GNNModel.lambda_loss2 + 0.5\n",
    "            GNNModel.lambda_loss3 = GNNModel.lambda_loss3 / 2\n",
    "        \n",
    "        loss,loss_per_node,h_loss,degree_loss,feature_loss = GNNModel(data.edge_index, data.x, neighbor_num_list, neighbor_dict, device=device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_per_node = loss_per_node.cpu().detach()\n",
    "        \n",
    "        h_loss = h_loss.cpu().detach()\n",
    "        degree_loss = degree_loss.cpu().detach()\n",
    "        feature_loss = feature_loss.cpu().detach()\n",
    "        \n",
    "        h_loss_norm = h_loss / (torch.max(h_loss) - torch.min(h_loss))\n",
    "        degree_loss_norm = degree_loss / (torch.max(degree_loss) - torch.min(degree_loss))\n",
    "        feature_loss_norm = feature_loss / (torch.max(feature_loss) - torch.min(feature_loss))\n",
    "        \n",
    "        comb_loss = args.h_loss_weight * h_loss_norm + args.degree_loss_weight *  degree_loss_norm + args.feature_loss_weight * feature_loss_norm\n",
    "        \n",
    "        if real_loss:\n",
    "            comp_loss = loss_per_node\n",
    "        else:\n",
    "            comp_loss = comb_loss\n",
    "            \n",
    "        \n",
    "        auc_score = eval_roc_auc(y.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score(benchmark/combined): \", auc_score)\n",
    "        \n",
    "        contextual_auc_score = eval_roc_auc(yc.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (contextual): \", contextual_auc_score)\n",
    "\n",
    "        dense_structural_auc_score = eval_roc_auc(ys.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (structural): \", dense_structural_auc_score)\n",
    "        \n",
    "        joint_type_auc_score = eval_roc_auc(yj.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (joint-type): \", joint_type_auc_score)\n",
    "        \n",
    "        structure_type_auc_score = eval_roc_auc(ysj.numpy(), comp_loss.numpy()) * 100\n",
    "        print(\"Dataset Name: \",dataset_str, \", AUC Score (structure type): \", structure_type_auc_score) \n",
    "        \n",
    "        best_auc = max(best_auc, auc_score)\n",
    "        best_auc_contextual = max(best_auc_contextual, contextual_auc_score)\n",
    "        best_auc_dense_structural = max(best_auc_dense_structural, dense_structural_auc_score)\n",
    "        best_auc_joint_type = max(best_auc_joint_structural, joint_type_auc_score)\n",
    "        best_auc_structure_type = max(best_auc_structure_type, structure_type_auc_score)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"===========================================================================================\")\n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score(benchmark/combined): \", best_auc)\n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (contextual): \", best_auc_contextual)\n",
    "\n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (structural): \", best_auc_dense_structural)\n",
    "        \n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (joint-type): \", best_auc_joint_type)\n",
    "        \n",
    "        \n",
    "        print(\"Dataset Name: \",dataset_str, \" Best AUC Score (structure type): \", best_auc_structure_type) \n",
    "        print(\"===========================================================================================\")\n",
    "        \n",
    "        \n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            arg_min_loss_per_node = loss_per_node\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss.cpu().detach()\n",
    "        loss_values.append(loss)\n",
    "        \n",
    "        \n",
    "        if args.plot_loss:\n",
    "\n",
    "            plt.plot(np.array(loss_values), 'r')\n",
    "            plt.show()\n",
    "    \n",
    "    return min_loss.item(), arg_min_loss_per_node.cpu().detach()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, embeddings, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(embeddings)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "def train_real_datasets(dataset_str, epoch_num = 10, lr = 5e-6, encoder = \"GCN\", \n",
    "                        lambda_loss1=1e-2, lambda_loss2=1e-3, lambda_loss3=1e-3, sample_size=8, loss_step=20, hidden_dim=None,\n",
    "                        real_loss=False,calculate_contextual=False,calculate_structural=False):\n",
    "    \n",
    "    data = load_data(dataset_str)\n",
    "    node_features = data.x\n",
    "    \n",
    "    if args.normalize_feat:\n",
    "    \n",
    "        node_features_min = node_features.min()\n",
    "        node_features_max = node_features.max()\n",
    "        node_features = (node_features - node_features_min)/node_features_max\n",
    "        data.x = node_features\n",
    "    \n",
    "    yc = []\n",
    "    ys = []\n",
    "    yj = []\n",
    "    \n",
    "    if calculate_contextual:\n",
    "        \n",
    "        if dataset_str == \"inj_cora\":\n",
    "            yc = data.y >> 0 & 1 # contextual outliers\n",
    "        else:\n",
    "            data, yc = gen_contextual_outliers(data=data,n=args.contextual_n,k=args.contextual_k)\n",
    "            \n",
    "        yc = yc.cpu().detach()\n",
    "    \n",
    "    \n",
    "    if calculate_structural:\n",
    "        \n",
    "        if dataset_str == \"inj_cora\":\n",
    "            ys = data.y >> 1 & 1 # structural outliers\n",
    "        else:\n",
    "            data, ys = gen_structural_outliers(data=data,n=args.structural_n,m=args.structural_m,p=0.2)\n",
    "            \n",
    "        ys = ys.cpu().detach()\n",
    "        data, yj = gen_joint_structural_outliers(data=data,n=args.structural_n,m=args.structural_m)\n",
    "        \n",
    "    \n",
    "    if args.use_combine_outlier:\n",
    "        data.y = torch.logical_or(ys, yc).int()\n",
    "        \n",
    "    ysj = torch.logical_or(ys, yj).int()\n",
    "    y = data.y.bool()    # binary labels (inlier/outlier)\n",
    "    y = y.cpu().detach()\n",
    "    \n",
    "    edge_index = data.edge_index.cpu()\n",
    "    \n",
    "    num_nodes = node_features.shape[0]\n",
    "    self_edges = torch.tensor([[i for i in range(num_nodes)],[i for i in range(num_nodes)]])\n",
    "    edge_index = torch.cat([edge_index,self_edges],dim=1)\n",
    "    data.edge_index = edge_index\n",
    "    data = data.to(device)\n",
    "    \n",
    "\n",
    "    loss, loss_per_node, = train(data, y, yc, ys, yj, ysj, lr=lr, epoch=epoch_num, device=device, encoder=encoder, lambda_loss1=lambda_loss1, \n",
    "          lambda_loss2=lambda_loss2, lambda_loss3=lambda_loss3, hidden_dim=hidden_dim, sample_size=sample_size,loss_step=loss_step,\n",
    "                                 real_loss=real_loss,calculate_contextual=calculate_contextual,calculate_structural=calculate_structural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a718ab-e1e0-49be-9748-dc4e8e0af644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ground truth neighbors Hv\n",
    "def generate_gt_neighbor(neighbor_dict, node_embeddings, neighbor_num_list, in_dim):\n",
    "    max_neighbor_num = max(neighbor_num_list)\n",
    "    all_gt_neighbor_embeddings = []\n",
    "    for i, embedding in enumerate(node_embeddings):\n",
    "        neighbor_indexes = neighbor_dict[i]\n",
    "        neighbor_embeddings = []\n",
    "        for index in neighbor_indexes:\n",
    "            neighbor_embeddings.append(node_embeddings[index].tolist())\n",
    "        if len(neighbor_embeddings) < max_neighbor_num:\n",
    "            for _ in range(max_neighbor_num - len(neighbor_embeddings)):\n",
    "                neighbor_embeddings.append(torch.zeros(in_dim).tolist())\n",
    "        all_gt_neighbor_embeddings.append(neighbor_embeddings)\n",
    "    return all_gt_neighbor_embeddings\n",
    "\n",
    "\n",
    "# Main Autoencoder structure here\n",
    "class GNNStructEncoder(nn.Module):\n",
    "    def __init__(self, in_dim0, in_dim, hidden_dim, layer_num, sample_size, device, neighbor_num_list, \n",
    "                 GNN_name=\"GIN\", norm_mode=\"PN-SCS\", norm_scale=20, lambda_loss1=0.01, lambda_loss2=0.001, lambda_loss3=0.0001):\n",
    "        \n",
    "        super(GNNStructEncoder, self).__init__()\n",
    "        \n",
    "        self.mlp0 = nn.Linear(in_dim0, hidden_dim)\n",
    "        self.norm = PairNorm(norm_mode, norm_scale)\n",
    "        self.out_dim = hidden_dim\n",
    "        self.lambda_loss1 = lambda_loss1\n",
    "        self.lambda_loss2 = lambda_loss2\n",
    "        self.lambda_loss3 = lambda_loss3\n",
    "        # GNN Encoder\n",
    "        if GNN_name == \"GIN\":\n",
    "            self.linear1 = MLP(layer_num, hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.graphconv1 = GINConv(self.linear1)\n",
    "            self.linear2 = MLP(layer_num, hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GINConv(self.linear2)\n",
    "        elif GNN_name == \"GCN\":\n",
    "            self.graphconv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        elif GNN_name == \"GAT\":\n",
    "            self.graphconv1 = GATConv(hidden_dim, hidden_dim)\n",
    "            self.graphconv2 = GATConv(hidden_dim, hidden_dim)\n",
    "        else:\n",
    "            self.graphconv1 = SAGEConv(hidden_dim, hidden_dim, aggr='sum')\n",
    "            # self.graphconv2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "            \n",
    "            # self.graphconv1 = GraphSAGE(hidden_dim, hidden_dim, aggr='mean', num_layers=1)\n",
    "            \n",
    "\n",
    "        self.neighbor_num_list = neighbor_num_list\n",
    "        self.tot_node = len(neighbor_num_list)\n",
    "\n",
    "        self.gaussian_mean = nn.Parameter(\n",
    "            torch.FloatTensor(sample_size, hidden_dim).uniform_(-0.5 / hidden_dim,\n",
    "                                                                                     0.5 / hidden_dim)).to(device)\n",
    "        self.gaussian_log_sigma = nn.Parameter(\n",
    "            torch.FloatTensor(sample_size, hidden_dim).uniform_(-0.5 / hidden_dim,\n",
    "                                                                                     0.5 / hidden_dim)).to(device)\n",
    "        self.m = torch.distributions.Normal(torch.zeros(sample_size, hidden_dim),\n",
    "                                            torch.ones(sample_size, hidden_dim))\n",
    "        \n",
    "        self.m_batched = torch.distributions.Normal(torch.zeros(sample_size, self.tot_node, hidden_dim),\n",
    "                                            torch.ones(sample_size, self.tot_node, hidden_dim))\n",
    "\n",
    "        self.m_h = torch.distributions.Normal(torch.zeros(sample_size, hidden_dim),\n",
    "                                            50* torch.ones(sample_size, hidden_dim))\n",
    "\n",
    "        # Before MLP Gaussian Means, and std\n",
    "\n",
    "        self.mlp_gaussian_mean = nn.Parameter(\n",
    "            torch.FloatTensor(hidden_dim).uniform_(-0.5 / hidden_dim, 0.5 / hidden_dim)).to(device)\n",
    "        self.mlp_gaussian_log_sigma = nn.Parameter(\n",
    "            torch.FloatTensor(hidden_dim).uniform_(-0.5 / hidden_dim, 0.5 / hidden_dim)).to(device)\n",
    "        self.mlp_m = torch.distributions.Normal(torch.zeros(hidden_dim), torch.ones(hidden_dim))\n",
    "\n",
    "        self.mlp_mean = FNN(hidden_dim, hidden_dim, hidden_dim, 3)\n",
    "        self.mlp_sigma = FNN(hidden_dim, hidden_dim, hidden_dim, 3)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "        self.mean_agg = SAGEConv(hidden_dim, hidden_dim, aggr='mean', normalize = False)\n",
    "        # self.mean_agg = GraphSAGE(hidden_dim, hidden_dim, aggr='mean', num_layers=1)\n",
    "        self.std_agg = PNAConv(hidden_dim, hidden_dim, aggregators=[\"std\"],scalers=[\"identity\"], deg=neighbor_num_list)        \n",
    "        self.layer1_generator = MLP_generator(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Decoders\n",
    "        self.degree_decoder = FNN(hidden_dim, hidden_dim, 1, 4)\n",
    "        self.feature_decoder = FNN(hidden_dim, hidden_dim, in_dim, 3)\n",
    "        self.degree_loss_func = nn.MSELoss()\n",
    "        self.feature_loss_func = nn.MSELoss()\n",
    "        self.pool = mp.Pool(4)\n",
    "        self.in_dim = in_dim\n",
    "        self.sample_size = sample_size \n",
    "        self.init_projection = FNN(in_dim, hidden_dim, hidden_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward_encoder(self, x, edge_index):\n",
    "        \n",
    "        # Apply graph convolution and activation, pair-norm to avoid trivial solution\n",
    "        h0 = self.mlp0(x)\n",
    "        l1 = self.graphconv1(h0, edge_index)\n",
    "        return l1, h0\n",
    "        \n",
    "        \n",
    "\n",
    "    # Sample neighbors from neighbor set, if the length of neighbor set less than sample size, then do the padding.\n",
    "    def sample_neighbors(self, indexes, neighbor_dict, gt_embeddings):\n",
    "        sampled_embeddings_list = []\n",
    "        mark_len_list = []\n",
    "        for index in indexes:\n",
    "            sampled_embeddings = []\n",
    "            neighbor_indexes = neighbor_dict[index]\n",
    "            if len(neighbor_indexes) < self.sample_size:\n",
    "                mask_len = len(neighbor_indexes)\n",
    "                sample_indexes = neighbor_indexes\n",
    "            else:\n",
    "                sample_indexes = random.sample(neighbor_indexes, self.sample_size)\n",
    "                mask_len = self.sample_size\n",
    "            for index in sample_indexes:\n",
    "                sampled_embeddings.append(gt_embeddings[index].tolist())\n",
    "            if len(sampled_embeddings) < self.sample_size:\n",
    "                for _ in range(self.sample_size - len(sampled_embeddings)):\n",
    "                    sampled_embeddings.append(torch.zeros(self.out_dim).tolist())\n",
    "            sampled_embeddings_list.append(sampled_embeddings)\n",
    "            mark_len_list.append(mask_len)\n",
    "        \n",
    "        return sampled_embeddings_list, mark_len_list\n",
    "    \n",
    "    def reconstruction_neighbors2(self, l1, h0, edge_index):\n",
    "                \n",
    "        recon_loss = 0\n",
    "        recon_loss_per_node = []\n",
    "    \n",
    "        sample_sz_per_node = [self.sample_size]* self.tot_node\n",
    "\n",
    "        # mean_neigh = self.graphconv1(h0, edge_index)\n",
    "        mean_neigh = self.mean_agg(h0, edge_index).detach()\n",
    "        std_neigh = self.std_agg(h0, edge_index).detach()\n",
    "        # mean_neigh = self.graphconv2(mean_neigh, edge_index)\n",
    "        # mean_neigh = l1\n",
    "        # mean_neigh = self.mean_agg(h0, edge_index, num_sampled_nodes_per_hop=sample_sz_per_node)\n",
    "        \n",
    "        \n",
    "        cov_neigh = torch.bmm(std_neigh.unsqueeze(dim=-1),std_neigh.unsqueeze(dim=1))\n",
    "        \n",
    "        target_mean = mean_neigh\n",
    "        target_cov = cov_neigh\n",
    "        \n",
    "        self_embedding = l1\n",
    "        # self_embedding = _normalize(self_embedding)\n",
    "        \n",
    "        self_embedding = self_embedding.unsqueeze(0)\n",
    "        self_embedding = self_embedding.repeat(self.sample_size, 1, 1)\n",
    "        generated_mean = self.mlp_mean(self_embedding)\n",
    "        generated_sigma = self.mlp_sigma(self_embedding)\n",
    "\n",
    "        \n",
    "        std_z = self.m_batched.sample().to(device)\n",
    "        var = generated_mean + generated_sigma.exp() * std_z\n",
    "        nhij = self.layer1_generator(var)\n",
    "        \n",
    "        generated_mean = torch.mean(nhij,dim=0)\n",
    "        generated_std = torch.std(nhij,dim=0)\n",
    "        generated_cov = torch.bmm(generated_std.unsqueeze(dim=-1),generated_std.unsqueeze(dim=1))/self.sample_size\n",
    "        \n",
    "        \n",
    "        tot_nodes = l1.shape[0]\n",
    "        h_dim = l1.shape[1]\n",
    "        \n",
    "        single_eye = torch.eye(h_dim).to(device)\n",
    "        single_eye = single_eye.unsqueeze(dim=0)\n",
    "        batch_eye = single_eye.repeat(tot_nodes,1,1)\n",
    "        \n",
    "        target_cov = target_cov + batch_eye\n",
    "        generated_cov = generated_cov + batch_eye\n",
    "\n",
    "        \n",
    "        det_target_cov = torch.linalg.det(target_cov) \n",
    "        det_generated_cov = torch.linalg.det(generated_cov) \n",
    "        trace_mat = torch.matmul(torch.inverse(generated_cov),target_cov)\n",
    "             \n",
    "        \n",
    "        x = torch.bmm(torch.unsqueeze(generated_mean - target_mean,dim=1),torch.inverse(generated_cov))\n",
    "        y = torch.unsqueeze(generated_mean - target_mean,dim=-1)\n",
    "        z = torch.bmm(x,y).squeeze()\n",
    "        \n",
    "        KL_loss = 0.5 * (torch.log(det_target_cov / det_generated_cov) - h_dim  + trace_mat.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1) + z)\n",
    "        \n",
    "        recon_loss = torch.mean(KL_loss)\n",
    "        recon_loss_per_node = KL_loss\n",
    "        \n",
    "        \n",
    "        return recon_loss, recon_loss_per_node\n",
    "    \n",
    "                \n",
    "        # self_embedding_min = self_embedding.min()\n",
    "        # self_embedding_max = self_embedding.max()\n",
    "        # self_embedding = (self_embedding - self_embedding_min)/(self_embedding_max+1e-14)\n",
    "        # generated_mean = self.mean_generator(self_embedding)\n",
    "        # generated_mean = _normalize(generated_mean)\n",
    "        # generated_std = self.std_generator(self_embedding)\n",
    "        # generated_std = _normalize(generated_std)\n",
    "        # generated_std = generated_std.abs().squeeze()\n",
    "        # generated_std = self.softplus(generated_std)\n",
    "        # generated_std = generated_std.exp().squeeze()\n",
    "        \n",
    "        # cov_x1 = (x1-mean_x1).transpose(1,0).matmul(x1-mean_x1) / max((nn-1),1)\n",
    "        # cov_x2 = (x2-mean_x2).transpose(1,0).matmul(x2-mean_x2) / max((nn-1),1)\n",
    "        \n",
    "        # generated_cov = generated_cov + torch.rand(generated_cov.shape).to(device)\n",
    "        # generated_cov = generated_cov * batch_eye\n",
    "        \n",
    "        # print(torch.isfinite(det_target_cov).all())\n",
    "        # print(torch.isfinite(det_generated_cov).all()) \n",
    "        \n",
    "        # KL_loss = 0.5 * (math.log(torch.det(cov_x1) / torch.det(cov_x2)) - h_dim  + torch.trace(torch.inverse(cov_x2).matmul(cov_x1)) \n",
    "        #     + (mean_x2 - mean_x1).reshape(1,-1).matmul(torch.inverse(cov_x2)).matmul(mean_x2 - mean_x1))\n",
    "    \n",
    "\n",
    "    def reconstruction_neighbors(self, FNN_generator, neighbor_indexes, neighbor_dict, from_layer, to_layer, device):\n",
    "        \n",
    "        \n",
    "        local_index_loss = 0\n",
    "        local_index_loss_per_node = []\n",
    "        sampled_embeddings_list, mark_len_list = self.sample_neighbors(neighbor_indexes, neighbor_dict, to_layer)\n",
    "        for i, neighbor_embeddings1 in enumerate(sampled_embeddings_list):\n",
    "            # Generating h^k_v, reparameterization trick\n",
    "            \n",
    "            # print(len(neighbor_embeddings1))\n",
    "            \n",
    "            index = neighbor_indexes[i]\n",
    "            mask_len1 = mark_len_list[i]\n",
    "            mean = from_layer[index].repeat(self.sample_size, 1)\n",
    "            mean = self.mlp_mean(mean)\n",
    "            sigma = from_layer[index].repeat(self.sample_size, 1)\n",
    "            sigma = self.mlp_sigma(sigma)\n",
    "            std_z = self.m.sample().to(device)\n",
    "            var = mean + sigma.exp() * std_z\n",
    "            nhij = FNN_generator(var)\n",
    "            \n",
    "            generated_neighbors = nhij\n",
    "            sum_neighbor_norm = 0\n",
    "            \n",
    "            for indexi, generated_neighbor in enumerate(generated_neighbors):\n",
    "                sum_neighbor_norm += torch.norm(generated_neighbor) / math.sqrt(self.out_dim)\n",
    "            generated_neighbors = torch.unsqueeze(generated_neighbors, dim=0).to(device)\n",
    "            target_neighbors = torch.unsqueeze(torch.FloatTensor(neighbor_embeddings1), dim=0).to(device)\n",
    "            \n",
    "            if args.neigh_loss == \"KL\":\n",
    "                KL_loss = KL_neighbor_loss(generated_neighbors, target_neighbors, mask_len1)\n",
    "                local_index_loss += KL_loss\n",
    "                local_index_loss_per_node.append(KL_loss)\n",
    "            \n",
    "            else:\n",
    "                W2_loss = W2_neighbor_loss(generated_neighbors, target_neighbors, mask_len1)\n",
    "                local_index_loss += W2_loss\n",
    "                local_index_loss_per_node.append(W2_loss)\n",
    "            \n",
    "            \n",
    "        local_index_loss_per_node = torch.stack(local_index_loss_per_node)\n",
    "        return local_index_loss, local_index_loss_per_node\n",
    "    \n",
    "\n",
    "    def neighbor_decoder(self, gij, ground_truth_degree_matrix, h0, neighbor_dict, device, h, edge_index):\n",
    "        \n",
    "        # Degree decoder below:\n",
    "        tot_nodes = gij.shape[0]\n",
    "        degree_logits = self.degree_decoding(gij)\n",
    "        ground_truth_degree_matrix = torch.unsqueeze(ground_truth_degree_matrix, dim=1)\n",
    "        degree_loss = self.degree_loss_func(degree_logits, ground_truth_degree_matrix.float())\n",
    "        degree_loss_per_node = (degree_logits-ground_truth_degree_matrix).pow(2)\n",
    "        _, degree_masks = torch.max(degree_logits.data, dim=1)\n",
    "        h_loss = 0\n",
    "        feature_loss = 0\n",
    "        # layer 1\n",
    "        loss_list = []\n",
    "        loss_list_per_node = []\n",
    "        feature_loss_list = []\n",
    "        # Sample multiple times to remove noise\n",
    "        for _ in range(3):\n",
    "            local_index_loss_sum = 0\n",
    "            local_index_loss_sum_per_node = []\n",
    "            indexes = []\n",
    "            h0_prime = self.feature_decoder(gij)\n",
    "            feature_losses = self.feature_loss_func(h0, h0_prime)\n",
    "            feature_losses_per_node = (h0-h0_prime).pow(2).mean(1)\n",
    "            feature_loss_list.append(feature_losses_per_node)\n",
    "            \n",
    "\n",
    "            \n",
    "            # local_index_loss, local_index_loss_per_node = self.reconstruction_neighbors(self.layer1_generator, indexes, neighbor_dict, gij, h0, device)\n",
    "            local_index_loss, local_index_loss_per_node = self.reconstruction_neighbors2(gij,h0,edge_index)\n",
    "            \n",
    "            # print(local_index_loss, local_index_loss2)\n",
    "            # print(local_index_loss_per_node, local_index_loss_per_node2)\n",
    "\n",
    "            loss_list.append(local_index_loss)\n",
    "            loss_list_per_node.append(local_index_loss_per_node)\n",
    "            \n",
    "        loss_list = torch.stack(loss_list)\n",
    "        h_loss += torch.mean(loss_list)\n",
    "        \n",
    "        loss_list_per_node = torch.stack(loss_list_per_node)\n",
    "        h_loss_per_node = torch.mean(loss_list_per_node,dim=0)\n",
    "        \n",
    "        feature_loss_per_node = torch.mean(torch.stack(feature_loss_list),dim=0)\n",
    "        feature_loss += torch.mean(torch.stack(feature_loss_list))\n",
    "                \n",
    "        h_loss_per_node = h_loss_per_node.reshape(tot_nodes,1)\n",
    "        degree_loss_per_node = degree_loss_per_node.reshape(tot_nodes,1)\n",
    "        feature_loss_per_node = feature_loss_per_node.reshape(tot_nodes,1)\n",
    "        \n",
    "        loss = self.lambda_loss1 * h_loss + degree_loss * self.lambda_loss3 + self.lambda_loss2 * feature_loss\n",
    "        loss_per_node = self.lambda_loss1 * h_loss_per_node + degree_loss_per_node * self.lambda_loss3 + self.lambda_loss2 * feature_loss_per_node\n",
    "        \n",
    "\n",
    "        return loss,loss_per_node,h_loss_per_node,degree_loss_per_node,feature_loss_per_node\n",
    "\n",
    "    def degree_decoding(self, node_embeddings):\n",
    "        degree_logits = F.relu(self.degree_decoder(node_embeddings))\n",
    "        return degree_logits\n",
    "\n",
    "    def forward(self, edge_index, x, ground_truth_degree_matrix, neighbor_dict, device):\n",
    "        \n",
    "        # Generate GNN encodings\n",
    "        l1, h0 = self.forward_encoder(x, edge_index)\n",
    "        loss, loss_per_node,h_loss,degree_loss,feature_loss = self.neighbor_decoder(l1, ground_truth_degree_matrix, h0, neighbor_dict, device, x, edge_index)\n",
    "        \n",
    "        return loss, loss_per_node,h_loss,degree_loss,feature_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33ad17-0dda-4225-a900-85f33f6680d1",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86955e8-54b2-4103-974d-98fff445534c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction\n",
      "Dataset:  inj_cora lr: 0.01 lambda_loss1 (neighbor): 0.01 lambda_loss2 (feature): 0.1 lambda_loss3 (degree): 0.8 sample_size: 10 dimension: 256 encoder: GCN loss_step: 5000 real_loss: False h_loss_weight: 1.0 feature_loss_weight 2.5 degree_loss_weight: 1.0 calculate_contextual True calculate_structural True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:04<?, ?it/s]\n",
      "/tmp/ipykernel_32771/3078169842.py:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Required Time: \" (en-st)*1000)\n",
      "/tmp/ipykernel_32771/3078169842.py:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Required Time: \" (en-st)*1000)\n",
      "/tmp/ipykernel_32771/3078169842.py:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Required Time: \" (en-st)*1000)\n",
      "/tmp/ipykernel_32771/3078169842.py:132: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Required Time: \" (en-st)*1000)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 678.00 MiB (GPU 0; 15.78 GiB total capacity; 13.93 GiB already allocated; 629.44 MiB free; 14.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset: \u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr:\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mlr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_loss1 (neighbor):\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mlambda_loss1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_loss2 (feature):\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mlambda_loss2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_loss3 (degree):\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mlambda_loss3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39msample_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension:\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mdimension, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder:\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mencoder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_step:\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mloss_step,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal_loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39mreal_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_loss_weight:\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mh_loss_weight,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_loss_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mfeature_loss_weight,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree_loss_weight:\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mdegree_loss_weight,\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate_contextual\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mcalculate_contextual,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate_structural\u001b[39m\u001b[38;5;124m\"\u001b[39m,args\u001b[38;5;241m.\u001b[39mcalculate_structural)\n\u001b[1;32m     38\u001b[0m dataset_str \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtrain_real_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_loss1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_loss1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43mlambda_loss2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_loss2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_loss3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_loss3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreal_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcalculate_contextual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_contextual\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcalculate_structural\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_structural\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 216\u001b[0m, in \u001b[0;36mtrain_real_datasets\u001b[0;34m(dataset_str, epoch_num, lr, encoder, lambda_loss1, lambda_loss2, lambda_loss3, sample_size, loss_step, hidden_dim, real_loss, calculate_contextual, calculate_structural)\u001b[0m\n\u001b[1;32m    212\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[1;32m    213\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 216\u001b[0m loss, loss_per_node, \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mysj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_loss1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_loss1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlambda_loss2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_loss2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_loss3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_loss3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mreal_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcalculate_contextual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculate_contextual\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcalculate_structural\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculate_structural\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, y, yc, ys, yj, ysj, lr, epoch, device, encoder, lambda_loss1, lambda_loss2, lambda_loss3, hidden_dim, sample_size, loss_step, real_loss, calculate_contextual, calculate_structural)\u001b[0m\n\u001b[1;32m     60\u001b[0m     GNNModel\u001b[38;5;241m.\u001b[39mlambda_loss2 \u001b[38;5;241m=\u001b[39m GNNModel\u001b[38;5;241m.\u001b[39mlambda_loss2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     61\u001b[0m     GNNModel\u001b[38;5;241m.\u001b[39mlambda_loss3 \u001b[38;5;241m=\u001b[39m GNNModel\u001b[38;5;241m.\u001b[39mlambda_loss3 \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 63\u001b[0m loss,loss_per_node,h_loss,degree_loss,feature_loss \u001b[38;5;241m=\u001b[39m \u001b[43mGNNModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_num_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m loss_per_node \u001b[38;5;241m=\u001b[39m loss_per_node\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     69\u001b[0m h_loss \u001b[38;5;241m=\u001b[39m h_loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/NWRGAE/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 325\u001b[0m, in \u001b[0;36mGNNStructEncoder.forward\u001b[0;34m(self, edge_index, x, ground_truth_degree_matrix, neighbor_dict, device)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, edge_index, x, ground_truth_degree_matrix, neighbor_dict, device):\n\u001b[1;32m    322\u001b[0m     \n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# Generate GNN encodings\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     l1, h0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_encoder(x, edge_index)\n\u001b[0;32m--> 325\u001b[0m     loss, loss_per_node,h_loss,degree_loss,feature_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_degree_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, loss_per_node,h_loss,degree_loss,feature_loss\n",
      "Cell \u001b[0;32mIn[5], line 290\u001b[0m, in \u001b[0;36mGNNStructEncoder.neighbor_decoder\u001b[0;34m(self, gij, ground_truth_degree_matrix, h0, neighbor_dict, device, h, edge_index)\u001b[0m\n\u001b[1;32m    285\u001b[0m feature_loss_list\u001b[38;5;241m.\u001b[39mappend(feature_losses_per_node)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# local_index_loss, local_index_loss_per_node = self.reconstruction_neighbors(self.layer1_generator, indexes, neighbor_dict, gij, h0, device)\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m local_index_loss, local_index_loss_per_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction_neighbors2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgij\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# print(local_index_loss, local_index_loss2)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# print(local_index_loss_per_node, local_index_loss_per_node2)\u001b[39;00m\n\u001b[1;32m    295\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(local_index_loss)\n",
      "Cell \u001b[0;32mIn[5], line 181\u001b[0m, in \u001b[0;36mGNNStructEncoder.reconstruction_neighbors2\u001b[0;34m(self, l1, h0, edge_index)\u001b[0m\n\u001b[1;32m    177\u001b[0m det_generated_cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(generated_cov) \n\u001b[1;32m    178\u001b[0m trace_mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(torch\u001b[38;5;241m.\u001b[39minverse(generated_cov),target_cov)\n\u001b[0;32m--> 181\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(torch\u001b[38;5;241m.\u001b[39munsqueeze(generated_mean \u001b[38;5;241m-\u001b[39m target_mean,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_cov\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    182\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(generated_mean \u001b[38;5;241m-\u001b[39m target_mean,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    183\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(x,y)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 678.00 MiB (GPU 0; 15.78 GiB total capacity; 13.93 GiB already allocated; 629.44 MiB free; 14.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "parser = argparse.ArgumentParser(description='parameters')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--dataset', type=str, default=\"inj_cora\")\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--epoch_num', type=int, default=500)\n",
    "parser.add_argument('--lambda_loss1', type=float, default=1e-2) #neighbor reconstruction loss weight\n",
    "parser.add_argument('--lambda_loss2', type=float, default=0.1) #feature loss weight\n",
    "parser.add_argument('--lambda_loss3', type=float, default=0.8) #degree loss weight\n",
    "parser.add_argument('--sample_size', type=int, default=10)\n",
    "parser.add_argument('--dimension', type=int, default=256)\n",
    "parser.add_argument('--encoder', type=str, default=\"GCN\")\n",
    "parser.add_argument('--loss_step', type=int, default=5000)\n",
    "parser.add_argument('--real_loss', type=bool, default=False) #use real loss or adaptive loss\n",
    "parser.add_argument('--neigh_loss', type=str, default=\"KL\")\n",
    "parser.add_argument('--h_loss_weight', type=float, default=1.0)#adaptive loss weight for h_loss\n",
    "parser.add_argument('--feature_loss_weight', type=float, default=2.5) #adaptive loss weight for feature loss\n",
    "parser.add_argument('--degree_loss_weight', type=float, default=1.0)#adaptive loss weight for degree loss\n",
    "parser.add_argument('--calculate_contextual', type=bool, default=True)\n",
    "parser.add_argument('--contextual_n', type=int, default=70)\n",
    "parser.add_argument('--contextual_k', type=int, default=10)\n",
    "parser.add_argument('--calculate_structural', type=bool, default=True)\n",
    "parser.add_argument('--structural_n', type=int, default=70)\n",
    "parser.add_argument('--structural_m', type=int, default=10)\n",
    "parser.add_argument('--use_combine_outlier', type=bool, default=False)\n",
    "parser.add_argument('--plot_loss', type=bool, default=True)\n",
    "parser.add_argument('--normalize_feat', type=bool, default=False)\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction\")\n",
    "print(\"Dataset: \", args.dataset, \"lr:\", args.lr, \"lambda_loss1 (neighbor):\",args.lambda_loss1, \"lambda_loss2 (feature):\", args.lambda_loss2, \"lambda_loss3 (degree):\", args.lambda_loss3, \"sample_size:\", args.sample_size, \"dimension:\",args.dimension, \"encoder:\", args.encoder, \"loss_step:\", args.loss_step,\"real_loss:\", args.real_loss, \"h_loss_weight:\",args.h_loss_weight,\"feature_loss_weight\",args.feature_loss_weight,\"degree_loss_weight:\",args.degree_loss_weight,\n",
    "\"calculate_contextual\",args.calculate_contextual,\"calculate_structural\",args.calculate_structural)\n",
    "\n",
    "\n",
    "dataset_str = args.dataset\n",
    "train_real_datasets(dataset_str=dataset_str, lr=args.lr, epoch_num=args.epoch_num, lambda_loss1=args.lambda_loss1, \n",
    "lambda_loss2=args.lambda_loss2, lambda_loss3=args.lambda_loss3, encoder=args.encoder, sample_size=args.sample_size, loss_step=args.loss_step, \n",
    "hidden_dim=args.dimension,real_loss=args.real_loss,calculate_contextual=args.calculate_contextual,calculate_structural=args.calculate_structural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192fd5d-01df-4836-ad62-07ff19227211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "m = torch.rand(5,3)\n",
    "s = torch.rand(5,3)\n",
    "\n",
    "n_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    a = torch.normal(mean=m, std=s)\n",
    "    a = a.unsqueeze(dim=0)\n",
    "    n_list.append(a)\n",
    "\n",
    "n_list = torch.cat(n_list,dim=0)\n",
    "print(n_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31459e-fb05-45c4-aec8-78ba6f6bb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb559b8-5adf-4ba9-b187-e37210382df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44d89c-5051-49a9-b0ea-afbda533c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.FloatTensor([10]* 100)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d245343-771a-45ac-9ad6-ad5b8e38f599",
   "metadata": {},
   "source": [
    "8 = 71.04\n",
    "16 = \n",
    "32 = \n",
    "64 = \n",
    "128 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0f536-23f6-4840-aa43-31cfe4e0a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN: 92.82 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NWRGAE",
   "language": "python",
   "name": "nwrgae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
